{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8974c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rdflib import Graph, Literal, Namespace, RDF, RDFS, OWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "128ba902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Namespaces\n",
    "BRICK = Namespace(\"https://brickschema.org/schema/Brick#\")\n",
    "BOT = Namespace(\"https://w3id.org/bot#\")\n",
    "INST = Namespace(\"https://lbd.example.com/\")\n",
    "\n",
    "PREFIXES = {\n",
    "    \"brick\": BRICK, \"bot\": BOT, \"inst\": INST, \"rdfs\": RDFS, \"owl\": OWL\n",
    "}\n",
    "\n",
    "# 1. CENTRALIZED TYPE MAPPING\n",
    "# Add new types here as your project grows\n",
    "TYPE_MAPPING = {\n",
    "    \"temperature\": BRICK.Room_Air_Temperature_Sensor,\n",
    "    \"co2\": BRICK.CO2_Sensor,\n",
    "    \"humidity\": BRICK.Humidity_Sensor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c62e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_sensor_instances(json_files_list):\n",
    "    \"\"\"\n",
    "    Reads multiple JSON files and creates a single graph with all sensors.\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    for p, ns in PREFIXES.items(): g.bind(p, ns)\n",
    "    \n",
    "    for file_path in json_files_list:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            print(f\"Processing {file_path}...\")\n",
    "            \n",
    "            for sensor in data.get(\"sensors\", []):\n",
    "                sensor_uuid = sensor.get(\"uuid\")\n",
    "                if not sensor_uuid: continue\n",
    "                \n",
    "                sensor_uri = INST[f\"sensor_{sensor_uuid}\"]\n",
    "                vendor_id = sensor.get(\"vendor_id\")\n",
    "                json_type = sensor.get(\"type\", \"\").lower()\n",
    "                \n",
    "                # Assign Brick class based on mapping, default to generic Sensor\n",
    "                brick_class = TYPE_MAPPING.get(json_type, BRICK.Sensor)\n",
    "                g.add((sensor_uri, RDF.type, brick_class))\n",
    "                \n",
    "                # Metadata\n",
    "                if vendor_id:\n",
    "                    g.add((sensor_uri, RDFS.label, Literal(vendor_id)))\n",
    "                if sensor.get(\"vendor\"):\n",
    "                    g.add((sensor_uri, RDFS.comment, Literal(sensor.get(\"vendor\"))))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "    \n",
    "    # Add hasPoint as the inverse of isPointOf\n",
    "    #g.add((BRICK.hasPoint, OWL.inverseOf, BRICK.isPointOf))\n",
    "            \n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0217c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_sensors_to_bot(sensor_graph, external_ttl_path):\n",
    "    \"\"\"\n",
    "    Links sensors to bot:Spaces and returns both the graph and match statistics.\n",
    "    \"\"\"\n",
    "    spatial_graph = Graph()\n",
    "    stats = {\n",
    "        \"total_sensors\": 0,\n",
    "        \"exact_matches\": 0,\n",
    "        \"fuzzy_matches\": 0,\n",
    "        \"no_matches\": 0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        spatial_graph.parse(external_ttl_path, format=\"turtle\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return sensor_graph, stats\n",
    "\n",
    "    # SPARQL for prioritized matching\n",
    "    query = \"\"\"\n",
    "        SELECT ?space ?label WHERE {\n",
    "            ?space rdf:type bot:Space .\n",
    "            ?space rdfs:label ?label .\n",
    "            BIND(STR(?label) AS ?sLabel)\n",
    "            FILTER(\n",
    "                LCASE(?sLabel) = LCASE(?target) || \n",
    "                STRSTARTS(LCASE(?target), LCASE(?sLabel))\n",
    "            )\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all sensor instances created\n",
    "    sensors = list(sensor_graph.subjects(RDF.type, None))\n",
    "    stats[\"total_sensors\"] = len(sensors)\n",
    "\n",
    "    for sensor_uri in sensors:\n",
    "        label_lit = sensor_graph.value(sensor_uri, RDFS.label)\n",
    "        if not label_lit:\n",
    "            stats[\"no_matches\"] += 1\n",
    "            continue\n",
    "            \n",
    "        target_str = str(label_lit)\n",
    "        results = spatial_graph.query(query, initBindings={'target': Literal(target_str)})\n",
    "        \n",
    "        matches = []\n",
    "        for row in results:\n",
    "            space_label = str(row.label)\n",
    "            # Scoring: 2 = Exact/Case-insensitive, 1 = Prefix\n",
    "            if target_str.lower() == space_label.lower():\n",
    "                score = 2\n",
    "            elif target_str.lower().startswith(space_label.lower()):\n",
    "                score = 1\n",
    "            else:\n",
    "                score = 0\n",
    "            matches.append((score, row.space))\n",
    "\n",
    "        if matches:\n",
    "            # Sort by score descending\n",
    "            matches.sort(key=lambda x: x[0], reverse=True)\n",
    "            best_score, best_space = matches[0]\n",
    "            \n",
    "            sensor_graph.add((sensor_uri, BRICK.isPointOf, best_space))\n",
    "            \n",
    "            if best_score == 2:\n",
    "                stats[\"exact_matches\"] += 1\n",
    "            else:\n",
    "                stats[\"fuzzy_matches\"] += 1\n",
    "        else:\n",
    "            stats[\"no_matches\"] += 1\n",
    "                \n",
    "    return sensor_graph, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d88be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_report(stats):\n",
    "    \"\"\"Prints a formatted table of the linking results.\"\"\"\n",
    "    total_found = stats[\"exact_matches\"] + stats[\"fuzzy_matches\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"SENSOR LINKING SUMMARY REPORT\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"{'Metric':<30} | {'Count':<7}\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"{'Total Sensors Processed':<30} | {stats['total_sensors']}\")\n",
    "    print(f\"{'Exact/Case-insensitive Matches':<30} | {stats['exact_matches']}\")\n",
    "    print(f\"{'Fuzzy (Prefix) Matches':<30} | {stats['fuzzy_matches']}\")\n",
    "    print(f\"{'Total Matches Found':<30} | {total_found}\")\n",
    "    print(f\"{'Sensors Without Relations':<30} | {stats['no_matches']}\")\n",
    "    print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ca9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_to_file(graph, output_filename):\n",
    "    graph.serialize(destination=output_filename, format=\"turtle\")\n",
    "    print(f\"Final graph saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b11254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\yanpe\\OneDrive - Metropolia Ammattikorkeakoulu Oy\\Research\\MD2MV\\data\\Sensors\\metadata\\sensors-temperature-org10-loc7-2025-12-17T10-16-30-253Z.json...\n",
      "Processing C:\\Users\\yanpe\\OneDrive - Metropolia Ammattikorkeakoulu Oy\\Research\\MD2MV\\data\\Sensors\\metadata\\sensors-co2-org10-loc7-2025-12-17T10-16-30-253Z.json...\n",
      "Processing C:\\Users\\yanpe\\OneDrive - Metropolia Ammattikorkeakoulu Oy\\Research\\MD2MV\\data\\Sensors\\metadata\\sensors-humidity-org10-loc7-2025-12-17T10-16-30-253Z.json...\n",
      "\n",
      "========================================\n",
      "SENSOR LINKING SUMMARY REPORT\n",
      "----------------------------------------\n",
      "Metric                         | Count  \n",
      "----------------------------------------\n",
      "Total Sensors Processed        | 1775\n",
      "Exact/Case-insensitive Matches | 1381\n",
      "Fuzzy (Prefix) Matches         | 288\n",
      "Total Matches Found            | 1669\n",
      "Sensors Without Relations      | 106\n",
      "========================================\n",
      "\n",
      "Final graph saved to C:\\Users\\yanpe\\OneDrive - Metropolia Ammattikorkeakoulu Oy\\Research\\MD2MV\\data\\TTL\\sensors_linked.ttl\n"
     ]
    }
   ],
   "source": [
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # List all your JSON files here\n",
    "    json_folder = r\"C:\\Users\\yanpe\\OneDrive - Metropolia Ammattikorkeakoulu Oy\\Research\\MD2MV\\data\\Sensors\\metadata\"\n",
    "    json_files = [\n",
    "        json_folder + \"\\\\sensors-temperature-org10-loc7-2025-12-17T10-16-30-253Z.json\", \n",
    "        json_folder + \"\\\\sensors-co2-org10-loc7-2025-12-17T10-16-30-253Z.json\", \n",
    "        json_folder + \"\\\\sensors-humidity-org10-loc7-2025-12-17T10-16-30-253Z.json\"\n",
    "    ]\n",
    "\n",
    "    # 1. Define instances\n",
    "    # (Assuming define_sensor_instances remains as previously discussed)\n",
    "    sensor_graph = define_sensor_instances(json_files)\n",
    "    \n",
    "    # 2. Link and get stats\n",
    "    ark_ttl_path = r\"C:\\Users\\yanpe\\OneDrive - Metropolia Ammattikorkeakoulu Oy\\Research\\MD2MV\\data\\TTL\\01ARK\\ARK_MET.ttl\"\n",
    "    sensor_graph, match_stats = link_sensors_to_bot(sensor_graph, ark_ttl_path)\n",
    "    \n",
    "    # 3. Print the report\n",
    "    print_summary_report(match_stats)\n",
    "    \n",
    "    # 4. Save\n",
    "    save_path = r\"C:\\Users\\yanpe\\OneDrive - Metropolia Ammattikorkeakoulu Oy\\Research\\MD2MV\\data\\TTL\\Linkset\\sensors_linked.ttl\"\n",
    "    save_graph_to_file(sensor_graph, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
